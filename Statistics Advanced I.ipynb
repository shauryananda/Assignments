{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab94c4d9-2671-4ec5-aadb-1305eff50de7",
   "metadata": {},
   "source": [
    "### Q1. What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35beccfd-be53-4211-8974-3d77397b109d",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are both mathematical functions used to describe the distribution of a random variable.\n",
    "\n",
    "The PMF is used for discrete random variables, while the PDF is used for continuous random variables.\n",
    "\n",
    "The PMF gives the probability of each possible value that the random variable can take. For example, suppose you flip a fair coin three times, and you want to know the probability of getting exactly two heads. The possible outcomes are: HHT, HTH, and THH. Each outcome has a probability of 1/8, so the PMF would be:\n",
    "\n",
    "PMF(X=0) = 1/8\n",
    "PMF(X=1) = 3/8\n",
    "PMF(X=2) = 3/8\n",
    "PMF(X=3) = 1/8\n",
    "\n",
    "Here, X is the random variable representing the number of heads obtained, and the PMF gives the probability of each possible value of X.\n",
    "\n",
    "The PDF, on the other hand, gives the probability density at each point in a continuous distribution. For example, suppose you have a continuous distribution representing the heights of people in a population, and you want to know the probability density at a height of 6 feet. The PDF would give you the height of the curve at that point.\n",
    "\n",
    "As an example, suppose the height of people in a population follows a normal distribution with mean 5.8 feet and standard deviation 0.3 feet. Then the PDF would be:\n",
    "\n",
    "PDF(x) = (1 / (0.3 * sqrt(2 * pi))) * exp(-(x - 5.8)^2 / (2 * 0.3^2))\n",
    "\n",
    "Here, x represents the height of a person, and the PDF gives the probability density at each height. For example, the PDF at a height of 6 feet would be:\n",
    "\n",
    "PDF(6) = (1 / (0.3 * sqrt(2 * pi))) * exp(-(6 - 5.8)^2 / (2 * 0.3^2))\n",
    "\n",
    "= 1.225\n",
    "\n",
    "This means that the probability density at a height of 6 feet is 1.225. Note that the PDF does not give the probability of a specific value of x, but rather the probability density at that point. The total area under the curve of the PDF is 1, representing the total probability of all possible values of x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc887c-b069-46b5-a72b-7e40ea3f1004",
   "metadata": {},
   "source": [
    "### Q2. What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de3c7c-1958-4db4-b69d-f016c872dad3",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a mathematical function that gives the probability that a random variable X is less than or equal to a given value x. It is defined for both discrete and continuous random variables.\n",
    "\n",
    "For a discrete random variable, the CDF is defined as the sum of all probabilities of the values less than or equal to the given value x. For a continuous random variable, the CDF is defined as the integral of the probability density function (PDF) up to the given value x.\n",
    "\n",
    "Here's an example of how the CDF works: Suppose you are rolling a six-sided die, and you want to know the probability of rolling a number less than or equal to 3. The possible outcomes are 1, 2, 3, 4, 5, and 6, each with a probability of 1/6. The CDF for this problem would be:\n",
    "\n",
    "F(x) = P(X <= x)\n",
    "\n",
    "F(1) = 1/6\n",
    "F(2) = 2/6\n",
    "F(3) = 3/6\n",
    "F(4) = 4/6\n",
    "F(5) = 5/6\n",
    "F(6) = 6/6 = 1\n",
    "\n",
    "So the CDF tells us that the probability of rolling a number less than or equal to 3 is 3/6, or 0.5. Similarly, the probability of rolling a number less than or equal to 4 is 4/6, or 0.67.\n",
    "\n",
    "The CDF is used to calculate probabilities for a range of values, rather than just a single value. It is also useful for comparing different distributions, as it allows us to compare the probabilities of different values across distributions. Additionally, the CDF can be used to generate random numbers from a given distribution, which is useful in simulation and modeling.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457855a-3492-48a6-9f2e-12060aeb1b50",
   "metadata": {},
   "source": [
    "### Q3. What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add4407-882c-494d-bcdb-6092a9a7418f",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is a commonly used probability distribution in statistics. It is often used as a model for real-world situations that exhibit a bell-shaped curve, where most values cluster around a central value, with fewer values at the extremes. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "Heights and weights of people: The distribution of heights and weights in a population often follow a normal distribution.\n",
    "\n",
    "Test scores: In a large population, test scores on a well-designed test often follow a normal distribution.\n",
    "\n",
    "Errors in measurements: Random errors in measurements, such as errors in lab experiments, often follow a normal distribution.\n",
    "\n",
    "Stock prices: The daily returns on stock prices often follow a normal distribution.\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the central value around which the distribution is centered, while the standard deviation represents the spread of the distribution.\n",
    "\n",
    "The shape of the normal distribution is symmetrical around the mean, with most values clustering around the mean and fewer values at the extremes. The mean is also the location of the peak of the distribution. The standard deviation determines the width of the distribution: a larger standard deviation results in a wider distribution, while a smaller standard deviation results in a narrower distribution.\n",
    "\n",
    "The normal distribution is often described as the 68-95-99.7 rule, which states that approximately 68% of the values fall within one standard deviation of the mean, approximately 95% of the values fall within two standard deviations of the mean, and approximately 99.7% of the values fall within three standard deviations of the mean.\n",
    "\n",
    "In summary, the normal distribution is a commonly used probability distribution for modeling real-world situations that exhibit a bell-shaped curve. The parameters of the normal distribution, the mean and standard deviation, describe the central value and spread of the distribution, respectively. The shape of the distribution is symmetrical around the mean, with most values clustering around the mean, and the standard deviation determines the width of the distribution.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dca2f2-3799-405a-8bb5-cedf667f2027",
   "metadata": {},
   "source": [
    "### Q4. Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269e6ce0-bbc0-4455-870b-e50345214f52",
   "metadata": {},
   "source": [
    "The Normal Distribution is one of the most important probability distributions in statistics and has many practical applications in various fields. Some of the key reasons why the Normal Distribution is important are:\n",
    "\n",
    "Many real-world phenomena follow a Normal Distribution: A large number of natural and social phenomena are known to follow a Normal Distribution, making it a useful tool for modeling and understanding these phenomena. Examples include height, weight, IQ scores, and blood pressure in humans, as well as measurements of physical quantities in engineering and science.\n",
    "\n",
    "It is well-understood and has many useful properties: The Normal Distribution has many useful mathematical properties, making it relatively easy to work with and calculate probabilities for a range of situations. It is also the basis for many statistical methods and tests.\n",
    "\n",
    "It provides a framework for hypothesis testing: The Normal Distribution is often used as a basis for hypothesis testing in statistics, allowing researchers to test whether observed data deviates significantly from what would be expected under a Normal Distribution.\n",
    "\n",
    "Some real-life examples of Normal Distribution include:\n",
    "\n",
    "IQ Scores: IQ scores are known to follow a Normal Distribution, with the mean IQ score around 100 and a standard deviation of 15. This distribution is useful for understanding the distribution of intelligence in a population.\n",
    "\n",
    "Height: Human height is also known to follow a Normal Distribution, with the mean height being around 5 feet 7 inches (170 cm) for males and 5 feet 4 inches (162.5 cm) for females in the US. This distribution can be useful in fields such as clothing design and ergonomics.\n",
    "\n",
    "Stock Market Returns: Daily returns on stocks and other financial assets often follow a Normal Distribution, with a mean return around zero and a standard deviation that varies depending on the asset. This distribution is useful for understanding the risk associated with different investments.\n",
    "\n",
    "Blood Pressure: Blood pressure in humans is known to follow a Normal Distribution, with a mean systolic pressure around 120 mmHg and a standard deviation of around 10 mmHg. This distribution is useful for understanding the distribution of blood pressure in a population and for diagnosing hypertension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadfd40b-f5ef-4b2f-80d7-024b13c5ca40",
   "metadata": {},
   "source": [
    "### Q5. What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea415ebb-3a66-4918-aa1d-20331fc1d52a",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a probability distribution that describes the outcome of a single binary (yes/no) experiment. The Bernoulli distribution has one parameter, which is the probability of success (p) in the experiment. The probability of failure (q) is simply 1-p. The probability mass function (PMF) of the Bernoulli distribution is:\n",
    "\n",
    "P(X = x) = p^x * (1-p)^(1-x)\n",
    "\n",
    "where X is the random variable that represents the outcome of the experiment (1 for success, 0 for failure), and x is its value (either 0 or 1).\n",
    "\n",
    "An example of the Bernoulli distribution is the probability of flipping a coin and getting heads. If we define heads as success (1) and tails as failure (0), then the probability of success (getting heads) is p=0.5, and the probability of failure (getting tails) is q=0.5. So the PMF of the Bernoulli distribution in this case is:\n",
    "\n",
    "P(X = 1) = 0.5^1 * (1-0.5)^(1-1) = 0.5\n",
    "\n",
    "P(X = 0) = 0.5^0 * (1-0.5)^(1-0) = 0.5\n",
    "\n",
    "The difference between the Bernoulli distribution and the binomial distribution is that the latter describes the number of successes in a fixed number (n) of independent Bernoulli trials, each with the same probability of success (p). In other words, the binomial distribution is the sum of n independent Bernoulli random variables, each with the same p.\n",
    "\n",
    "The probability mass function (PMF) of the binomial distribution is:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1-p)^(n-k)\n",
    "\n",
    "where X is the random variable that represents the number of successes in n trials, k is its value (between 0 and n), and (n choose k) is the binomial coefficient that represents the number of ways to choose k successes out of n trials.\n",
    "\n",
    "For example, if we flip a coin 10 times and count the number of times we get heads (success), the distribution of the number of heads will be a binomial distribution with n=10 and p=0.5. The PMF of this distribution will give us the probabilities of getting 0, 1, 2, ..., or 10 heads in 10 flips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2924821-1b01-44a9-8668-5ee0568d3d5f",
   "metadata": {},
   "source": [
    "### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the datasetis normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910731e-ff45-490a-bcd5-cd4b76be4849",
   "metadata": {},
   "source": [
    "To find the probability that a randomly selected observation from a normal distribution with mean μ and standard deviation σ will be greater than a certain value x, we need to calculate the area under the normal curve to the right of x. This can be done using the standard normal distribution table or using software, but we can also use the z-score formula to convert x to a standard normal variable and then look up the probability from a standard normal distribution table.\n",
    "\n",
    "The z-score formula is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where z is the standard normal variable, x is the value we want to convert, μ is the mean of the normal distribution, and σ is the standard deviation of the normal distribution.\n",
    "\n",
    "In this case, we want to find the probability of a randomly selected observation being greater than 60, so x = 60, μ = 50, and σ = 10. Therefore, the z-score is:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "probability of a standard normal variable being greater than 1 from a standard normal distribution table. \n",
    "\n",
    "Using a table, we find that the probability is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from this normal distribution will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f9172-4de6-4803-ba4a-610c1943cc86",
   "metadata": {},
   "source": [
    "### Q7. Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4d299-6dc2-49ba-9054-03a875810b06",
   "metadata": {},
   "source": [
    "The uniform distribution is a probability distribution that describes a continuous random variable with a constant probability density function (PDF) over a specified range. This means that the probability of the random variable taking any value within the range is the same.\n",
    "\n",
    "The PDF of the uniform distribution is:\n",
    "\n",
    "f(x) = 1/(b-a), for a ≤ x ≤ b\n",
    "\n",
    "where a and b are the endpoints of the range of the distribution, and f(x) is the probability density function. The mean of the uniform distribution is (a+b)/2, and the variance is (b-a)^2/12.\n",
    "\n",
    "An example of the uniform distribution is the roll of a fair six-sided die. Assuming the die is fair, each face has an equal probability of being rolled, so the probability of rolling any number between 1 and 6 is 1/6. The range of the uniform distribution in this case is a=1 and b=6, so the PDF is:\n",
    "\n",
    "f(x) = 1/6, for 1 ≤ x ≤ 6\n",
    "\n",
    "This means that the probability of rolling any number between 1 and 6 is the same (1/6). The mean of the uniform distribution is (1+6)/2 = 3.5, which is the expected value of a roll of the die. The variance of the uniform distribution is (6-1)^2/12 = 2.92, which describes the spread of the distribution around the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e5b1fb-9f1f-4bc5-878b-b4997216d629",
   "metadata": {},
   "source": [
    "### Q8. What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2970bb-57e0-4c3d-8774-c0681e1c1506",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a measure of how many standard deviations a data point is away from the mean of a distribution. It is a standardized value that helps to compare values from different distributions.\n",
    "\n",
    "The formula for calculating the z-score is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the data point, μ is the mean of the distribution, and σ is the standard deviation of the distribution.\n",
    "\n",
    "The z-score is important because it allows us to standardize data and make meaningful comparisons between data points from different distributions. A positive z-score indicates that the data point is above the mean of the distribution, while a negative z-score indicates that the data point is below the mean. A z-score of 0 indicates that the data point is exactly at the mean.\n",
    "\n",
    "Using the z-score, we can calculate probabilities of obtaining certain values or ranges of values in a normal distribution. We can use tables or software to find the area under the normal distribution curve corresponding to a certain z-score. For example, we can find the probability of obtaining a z-score of 1.5 or greater by looking up the area under the curve to the right of the z-score of 1.5.\n",
    "\n",
    "The z-score is also useful in identifying outliers, which are data points that are significantly different from the rest of the data. Outliers are typically defined as data points with z-scores greater than a certain threshold, such as 2 or 3 standard deviations away from the mean.\n",
    "\n",
    "Overall, the z-score is a powerful tool in statistics and data analysis that allows us to standardize data and make meaningful comparisons and probability calculations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1570a12a-246f-40f0-b7f3-f7bbfb0e1302",
   "metadata": {},
   "source": [
    "### Q9. What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c0233-4d6c-48a3-af23-45e063048e9a",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the sample means and sums of many independent and identically distributed random variables. It states that as the sample size increases, the distribution of the sample means or sums tends to become normal, regardless of the distribution of the underlying population.\n",
    "\n",
    "More formally, the Central Limit Theorem states that the sample mean of n independent and identically distributed random variables, X1, X2, ..., Xn, with mean μ and standard deviation σ, approaches a normal distribution with mean μ and standard deviation σ/√n, as n approaches infinity.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it allows us to make inferences about the population parameters, such as the mean and standard deviation, based on a sample of data. This is important because it is often impractical or impossible to collect data on an entire population, and we must rely on samples to make statistical inferences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e87e82-f8f9-4fe8-8ef5-5344e7db8896",
   "metadata": {},
   "source": [
    "The Central Limit Theorem is also important in hypothesis testing, where we use statistical tests to determine whether a difference between groups or a relationship between variables is statistically significant. The Central Limit Theorem allows us to assume normality of the sampling distribution of the sample means, which is a key assumption in many statistical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c284bb7-1ad7-43c6-9983-8fcced5fd0a6",
   "metadata": {},
   "source": [
    "### Q10. State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aee789-604c-4ae1-867b-43a963c24fb8",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) relies on certain assumptions in order to hold true. The assumptions of the Central Limit Theorem include:\n",
    "\n",
    "Independence: The random variables in the sample are independent of each other. This means that the value of one variable does not influence the value of any other variable in the sample.\n",
    "\n",
    "Identical Distribution: The random variables in the sample are identically distributed. This means that they have the same probability distribution, including the same mean and standard deviation.\n",
    "\n",
    "Finite Variance: The population from which the sample is drawn has a finite variance. This assumption ensures that the sample means and sums are well-defined and have a finite variance as well.\n",
    "\n",
    "Random Sampling: The sample is drawn at random from the population. This means that each member of the population has an equal chance of being included in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79d427-5e00-40f2-8c59-688f3ef16f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
